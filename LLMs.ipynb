{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayfaLK/Projects/blob/master/LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4By3Fq4o3j2"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi\n",
        "!pip install kaleido\n",
        "!pip install python-multipart\n",
        "!pip install uvicorn\n",
        "!pip install cohere tiktoken\n",
        "!pip install llmx\n",
        "!pip install --upgrade llmx\n",
        "!pip install openpyxl\n",
        "!pip install --upgrade pandas\n",
        "!pip install openai\n",
        "!pip install replicate\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import replicate\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import pylab\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju-ldnUlpMZp"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Extraire le nom du fichier\n",
        "file_name = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeiOo-FAIMoL"
      },
      "outputs": [],
      "source": [
        "def split_words_on_uppercase(input_string):\n",
        "    result = []\n",
        "    current_word = \"\"\n",
        "\n",
        "    for char in input_string:\n",
        "        # Check if the character is uppercase\n",
        "        if char.isupper():\n",
        "            # Add the current word to the result list\n",
        "            result.append(current_word)\n",
        "            # Start a new word with the uppercase character\n",
        "            current_word = char\n",
        "        else:\n",
        "            # Continue building the current word\n",
        "            current_word += char\n",
        "\n",
        "    # Add the last word to the result list\n",
        "    result.append(current_word)\n",
        "\n",
        "    # Join the words with a space and return the result\n",
        "    return ' '.join(result).strip()  # Remove leading and trailing spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuT9VWj6EExI"
      },
      "outputs": [],
      "source": [
        "import chardet\n",
        "import pandas as pd\n",
        "\n",
        "# Function to detect encoding\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        result = chardet.detect(f.read())\n",
        "    return result['encoding']\n",
        "# Get the detected encoding\n",
        "detected_encoding = detect_encoding(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZmv7-aGpNEJ"
      },
      "outputs": [],
      "source": [
        "#file = 'AwardToArtist.csv'\n",
        "file_name = os.path.basename(file_name)\n",
        "print (file_name)\n",
        "file_name_without_extension = os.path.splitext(file_name)[0]\n",
        "\n",
        "\n",
        "cleaned2 = file_name_without_extension.split(\"To\")\n",
        "\n",
        "partie1 = cleaned2[0]\n",
        "partie2 = cleaned2[1]\n",
        "\n",
        "print(partie1)\n",
        "print(partie2)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "#print(partie1)\n",
        "#print(partie2)\n",
        "input_string = partie1\n",
        "partie11 = split_words_on_uppercase(input_string)\n",
        "print(partie11)\n",
        "input_string = partie2\n",
        "partie22 = split_words_on_uppercase(input_string)\n",
        "print(partie22)\n",
        "\n",
        "\n",
        "db = pd.read_csv(file_name, engine='python',encoding = detected_encoding, on_bad_lines='skip')\n",
        "current_columns = db.columns\n",
        "\n",
        "# Renommez les colonnes en utilisant leurs indices\n",
        "db.columns = [partie1, partie2]\n",
        "\n",
        "# Affichez le DataFrame mis à jour\n",
        "print(db)\n",
        "\n",
        "# Remove rows with empty elements\n",
        "db = db.dropna()\n",
        "db = db.drop_duplicates()\n",
        "# Replace or remove non-alphanumeric characters in a specific column\n",
        "db[partie1] = db[partie1].str.replace(r'[^a-zA-Z0-9\\s.]', '', regex=True)\n",
        "db[partie2] = db[partie2].str.replace(r'[^a-zA-Z0-9\\s.]', '', regex=True)\n",
        "# Save the cleaned DataFrame back to a new CSV file\n",
        "cleaned_file_name = f\"cleaned{file_name}\"\n",
        "db.to_csv(cleaned_file_name, index=False)\n",
        "db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from replicate.client import Client\n",
        "\n",
        "replicate = Client(api_token=\"...\")"
      ],
      "metadata": {
        "id": "Wt7-9oUk9p4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynfXOiTJpRG4"
      },
      "outputs": [],
      "source": [
        "#os.environ[\"REPLICATE_API_TOKEN\"] = \"..\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#token = \"...\""
      ],
      "metadata": {
        "id": "qSkQKOqj5pPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT FORMAT**"
      ],
      "metadata": {
        "id": "nBwpBbEmkopi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Créez une variable pour stocker les noms de fichiers\n",
        "similarity_files = []\n",
        "json_result_list = []\n",
        "\n",
        "# Create an empty list to store all JSON items\n",
        "all_json_items = []\n",
        "\n",
        "liste_examples = []\n",
        "liste_answer = []\n",
        "# Nombre total d'itérations (adaptez-le à votre cas)\n",
        "nombre_iterations = 3\n",
        "for i in range(nombre_iterations):\n",
        "  #all_ceos_xml = ET.Element('all_ceos')\n",
        "  # Mesurer le temps d'exécution initial\n",
        "  temps_debut = time.time()\n",
        "  print(f\"*****************************Iteration {i+1}*********************************\")\n",
        "  premiere_iteration = True\n",
        "\n",
        "  # Convertissez le DataFrame en une liste à chaque itération\n",
        "  ma_liste = db.values.tolist()\n",
        "  elements_choisis = random.sample(ma_liste, 5)\n",
        "\n",
        "  #print(f\"Éléments choisis: {elements_choisis}\")\n",
        "  for j in range(len(elements_choisis)):\n",
        "    Example_j = elements_choisis[j][0]\n",
        "    Answer_j = elements_choisis[j][1]\n",
        "    liste_examples.append(Example_j)\n",
        "    liste_answer.append(Answer_j)\n",
        "    #print(f\"Example_{j}: {Example_j}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Supprimez les éléments choisis de la liste principale\n",
        "  for element in elements_choisis:\n",
        "      ma_liste.remove(element)\n",
        "\n",
        "  #print(f\"Reste de la liste: {ma_liste}\")\n",
        "\n",
        "  batch_size = 8\n",
        "  total_rows = len(ma_liste)\n",
        "  num_batches = (total_rows + batch_size - 1) // batch_size  # Calculating the number of batches\n",
        "\n",
        "  for batch_index in range(num_batches):\n",
        "    #print(f\"Batch:\",{batch_index+1})\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = min((batch_index + 1) * batch_size, total_rows)\n",
        "    batch_list = ma_liste[start_index:end_index]\n",
        "    #print(f\"Batch List: {batch_list}\")\n",
        "\n",
        "    # prendre la premiere colonne de la liste \"ma_liste\" et le mettre dans \"output_list\"\n",
        "    output_list = []\n",
        "    for row in batch_list:\n",
        "        output_list.append(row[0])\n",
        "\n",
        "    # Cette ligne de code transforme une liste d'éléments en une chaîne de caractères où les éléments sont séparés par des virgules et un espace.\n",
        "    formatted_output = ', '.join(output_list)\n",
        "\n",
        "\n",
        "\n",
        "    input_data = {\n",
        "          \"prompt\": f\"\"\"Look at this examples: \\n\\\n",
        "        Example: {liste_examples[0]} \\n\\\n",
        "        Answer: {liste_answer[0]}\\n\\\n",
        "        Example: {liste_examples[1]} \\n\\\n",
        "        Answer: {liste_answer[1]}\\n\\\n",
        "        Example: {liste_examples[2]} \\n\\\n",
        "        Answer: {liste_answer[2]}\\n\\\n",
        "        Example: {liste_examples[3]} \\n\\\n",
        "        Answer: {liste_answer[3]}\\n\\\n",
        "        Example: {liste_examples[4]} \\n\\\n",
        "        Answer: {liste_answer[4]}\\n\\\n",
        "        I order you to focus carefully on my prompt before answering. \\n\\\n",
        "        complete the {partie22} of each one of this list: {formatted_output} \\n\\\n",
        "        you should provide me just {len(batch_list)} rows. \\n\\\n",
        "        If you don't know the answer please write 'unknown' \\n\\\n",
        "        If more than one answer fit for {partie22} write only the first option\"\"\",\n",
        "        \"system_prompt\": fr\"\"\"You are a semantic data transformer.\\n\\\n",
        "        Provide the answer in this format: \\n\\\n",
        "        {partie11}: \\n\\\n",
        "        {partie22}: \\n\\\n",
        "        Do not write explanations. Do not type questions unless I instruct you to do so.\"\"\"\n",
        "      }\n",
        "\n",
        "    print(f\"Prompt: {input_data}\")\n",
        "\n",
        "    output_prompt2 = replicate.run(\n",
        "        \"replicate/llama-2-70b-chat:58d078176e02c219e11eb4da5a02a7830a283b14cf8f94537af893ccff5ee781\", input=input_data)\n",
        "    full_response_prompt2 = \"\".join(output_prompt2)\n",
        "\n",
        "    print(full_response_prompt2)\n",
        "    # Extract answers from the response using regex\n",
        "    matches = re.findall(rf\"{partie11}: (.+?)\\n{partie22}: (.+?)\\n\", full_response_prompt2)\n",
        "    # Extend data_list with matches from this iteration\n",
        "    address_list = []\n",
        "    address_list.extend(matches)\n",
        "\n",
        "\n",
        "    # Create a CSV file to save the JSON data for this iteration\n",
        "    csv_file_name = f\"output_{i+1}.csv\"\n",
        "\n",
        "    # Déterminez le mode d'ouverture en fonction de l'itération et premiere_iteration\n",
        "    if premiere_iteration:\n",
        "      mode = 'w'\n",
        "    else:\n",
        "      mode = 'a'\n",
        "\n",
        "\n",
        "    with open(csv_file_name, mode=mode, newline='') as csv_file:\n",
        "        # Créer un écrivain CSV\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        if premiere_iteration:\n",
        "          # Écrire l'en-tête dans le fichier CSV\n",
        "          csv_writer.writerow([partie1, partie2])\n",
        "\n",
        "        # Write data\n",
        "        for data in address_list:\n",
        "          address = data[0]\n",
        "          state_world = data[1]\n",
        "          csv_writer.writerow([address, state_world])\n",
        "\n",
        "    # Imprimer un message indiquant que les données CSV ont été sauvegardées\n",
        "    print(f'Données CSV ont été sauvegardées dans {csv_file_name}')\n",
        "    premiere_iteration = False\n",
        "  # Assuming you have defined 'df' and 'csv_file_name' variables earlier in your code\n",
        "  df2 = pd.read_csv(f'output_{i+1}.csv')\n",
        "  # Créez une liste vide pour stocker les lignes de df3\n",
        "  result_rows = []\n",
        "\n",
        "  # Parcourez les lignes de df\n",
        "  for index, row_df in db.iterrows():\n",
        "    airport_df = row_df[partie1]\n",
        "    country_df = row_df[partie2]\n",
        "\n",
        "    # Recherchez si la ligne existe dans df2 en fonction de la colonne \"airport\"\n",
        "    matching_row_df2 = df2[df2[partie1] == airport_df]\n",
        "\n",
        "    if not matching_row_df2.empty:\n",
        "      airport_df2 = matching_row_df2[partie1].iloc[0]\n",
        "      country_df2 = matching_row_df2[partie2].iloc[0]\n",
        "\n",
        "      # Calculez la similarité entre les éléments correspondants (vous pouvez personnaliser cette logique)\n",
        "      similarity = 1 if country_df == country_df2 else 0\n",
        "\n",
        "      # Ajoutez la ligne à la liste\n",
        "      result_rows.append([country_df, country_df2, similarity])\n",
        "\n",
        "  # Créez un DataFrame df3 à partir de la liste\n",
        "  df3 = pd.DataFrame(result_rows, columns=[ 'data_from_df', 'data_from_df2', 'similarity'])\n",
        "\n",
        "  # Affichez df3\n",
        "  print(df3)\n",
        "\n",
        "  # Enregistrer le DataFrame df3 dans un fichier CSV\n",
        "  df3.to_csv(f'Similarity_{i+1}.csv', index=False)\n",
        "\n",
        "  # Print a message indicating that the data has been saved\n",
        "  print(f'Data with similarity values has been saved to \\'Similarity_{i+1}.csv\\'')\n",
        "\n",
        "  # Mesurer le temps d'exécution final\n",
        "  temps_fin = time.time()\n",
        "  temps_execution = temps_fin - temps_debut\n",
        "  # Convertir le temps en minutes et secondes\n",
        "  minutes = int(temps_execution // 60)\n",
        "  secondes = int(temps_execution % 60)\n",
        "  # Formater le temps en chaîne de caractères\n",
        "  temps_formate = f\"{minutes} min {secondes} s\"\n",
        "\n",
        "  # Enregistrez le temps d'exécution formate dans un fichier texte\n",
        "  with open(f'temps_execution_{i+1}.txt', 'w') as fichier_temps:\n",
        "    fichier_temps.write(f'Temps d\\'exécution total : {temps_formate}')\n",
        "\n",
        "  # Affichez le temps d'exécution formate\n",
        "  print(f\"Temps d'exécution total : {temps_formate}\")\n"
      ],
      "metadata": {
        "id": "BJoOF7dclakX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XML FORMAT**"
      ],
      "metadata": {
        "id": "5nlpDLvMYxX1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32VPf4slxUyq"
      },
      "source": [
        "# Fonction extraire xml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rxQRiGYmXS4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_text_between_tags(text, tag_name):\n",
        "    pattern = f\"<{tag_name}>((?:(.|\\n)+?)?)</{tag_name}>\"\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    else:\n",
        "        raise ValueError(f\"No {tag_name} tag found in the text\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "# Créez une variable pour stocker les noms de fichiers\n",
        "similarity_files = []\n",
        "\n",
        "# Create an empty list to store all JSON items\n",
        "all_json_items = []\n",
        "\n",
        "liste_examples = []\n",
        "liste_answer = []\n",
        "# Nombre total d'itérations (adaptez-le à votre cas)\n",
        "nombre_iterations = 3\n",
        "for i in range(nombre_iterations):\n",
        "  #all_ceos_xml = ET.Element('all_ceos')\n",
        "  # Mesurer le temps d'exécution initial\n",
        "  temps_debut = time.time()\n",
        "  print(f\"*****************************Iteration {i+1}*********************************\")\n",
        "  premiere_iteration = True\n",
        "\n",
        "  # Convertissez le DataFrame en une liste à chaque itération\n",
        "  ma_liste = db.values.tolist()\n",
        "  elements_choisis = random.sample(ma_liste, 5)\n",
        "\n",
        "  #print(f\"Éléments choisis: {elements_choisis}\")\n",
        "  for j in range(len(elements_choisis)):\n",
        "    Example_j = elements_choisis[j][0]\n",
        "    Answer_j = elements_choisis[j][1]\n",
        "    liste_examples.append(Example_j)\n",
        "    liste_answer.append(Answer_j)\n",
        "    #print(f\"Example_{j}: {Example_j}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Supprimez les éléments choisis de la liste principale\n",
        "  for element in elements_choisis:\n",
        "      ma_liste.remove(element)\n",
        "\n",
        "  #print(f\"Reste de la liste: {ma_liste}\")\n",
        "\n",
        "  batch_size = 8\n",
        "  total_rows = len(ma_liste)\n",
        "  num_batches = (total_rows + batch_size - 1) // batch_size  # Calculating the number of batches\n",
        "\n",
        "  for batch_index in range(num_batches):\n",
        "    #print(f\"Batch:\",{batch_index+1})\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = min((batch_index + 1) * batch_size, total_rows)\n",
        "    batch_list = ma_liste[start_index:end_index]\n",
        "    #print(f\"Batch List: {batch_list}\")\n",
        "\n",
        "    # prendre la premiere colonne de la liste \"ma_liste\" et le mettre dans \"output_list\"\n",
        "    output_list = []\n",
        "    for row in batch_list:\n",
        "        output_list.append(row[0])\n",
        "\n",
        "    # Cette ligne de code transforme une liste d'éléments en une chaîne de caractères où les éléments sont séparés par des virgules et un espace.\n",
        "    formatted_output = ', '.join(output_list)\n",
        "\n",
        "\n",
        "\n",
        "    input_data = {\n",
        "          \"prompt\": f\"Act as Senior data analyst, \\n\\\n",
        "        Look at this examples: \\n\\\n",
        "        Example: {liste_examples[0]} \\n\\\n",
        "        Answer: {liste_answer[0]}\\n\\\n",
        "        Example: {liste_examples[1]} \\n\\\n",
        "        Answer: {liste_answer[1]}\\n\\\n",
        "        Example: {liste_examples[2]} \\n\\\n",
        "        Answer: {liste_answer[2]}\\n\\\n",
        "        Example: {liste_examples[3]} \\n\\\n",
        "        Answer: {liste_answer[3]}\\n\\\n",
        "        Example: {liste_examples[4]} \\n\\\n",
        "        Answer: {liste_answer[4]}\\n\\\n",
        "        I order you to focus carefully on my prompt before answering: \\n\\\n",
        "        complete the {partie22} of each one of this list: {formatted_output} \\n\\\n",
        "        Provide the result in string format, that begining with 'TEXTBEGIN' and ending with 'TEXTEND'.\\n\\\n",
        "        you should provide me just {len(batch_list)} rows. \\n\\\n",
        "        If you don't know the answer please write 'unknown' \\n\\\n",
        "        If more than one answer fit for {partie22} write only the first option\"\n",
        "\n",
        "\n",
        "      }\n",
        "\n",
        "    #print(f\"Prompt: {input_data}\")\n",
        "\n",
        "    output_prompt2 = replicate.run(\n",
        "        \"replicate/llama-2-70b-chat:58d078176e02c219e11eb4da5a02a7830a283b14cf8f94537af893ccff5ee781\", input=input_data)\n",
        "    full_response_prompt2 = \"\".join(output_prompt2)\n",
        "\n",
        "    print( full_response_prompt2)\n",
        "    TEXT = extract_text_between_tags(full_response_prompt2, \"query\")\n",
        "    #print(\"TEXXXXXXXXXXXT\",TEXT)\n",
        "    # Analyser le XML\n",
        "    root = ET.fromstring(TEXT)\n",
        "    # Create a CSV file to save the JSON data for this iteration\n",
        "    csv_file_name = f\"output_{i+1}.csv\"\n",
        "\n",
        "    # Déterminez le mode d'ouverture en fonction de l'itération et premiere_iteration\n",
        "    if premiere_iteration:\n",
        "      mode = 'w'\n",
        "    else:\n",
        "      mode = 'a'\n",
        "\n",
        "\n",
        "    with open(csv_file_name, mode=mode, newline='') as csv_file:\n",
        "        # Créer un écrivain CSV\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        if premiere_iteration:\n",
        "          # Écrire l'en-tête dans le fichier CSV\n",
        "          csv_writer.writerow([partie1, partie2])\n",
        "\n",
        "        # Parcourir chaque élément 'ceo' dans le XML\n",
        "        for ceo_element in root.findall('.//row'):\n",
        "            # Extraire les valeurs d'adresse et de State_World\n",
        "            address = ceo_element.find(partie1).text\n",
        "            state_world = ceo_element.find(partie2).text\n",
        "\n",
        "            # Écrire les valeurs dans le fichier CSV\n",
        "            csv_writer.writerow([address, state_world])\n",
        "\n",
        "    # Imprimer un message indiquant que les données CSV ont été sauvegardées\n",
        "    print(f'Données CSV ont été sauvegardées dans {csv_file_name}')\n",
        "    premiere_iteration = False\n",
        "  # Assuming you have defined 'df' and 'csv_file_name' variables earlier in your code\n",
        "  df2 = pd.read_csv(f'output_{i+1}.csv')\n",
        "  # Créez une liste vide pour stocker les lignes de df3\n",
        "  result_rows = []\n",
        "\n",
        "  # Parcourez les lignes de df\n",
        "  for index, row_df in db.iterrows():\n",
        "    airport_df = row_df[partie1]\n",
        "    country_df = row_df[partie2]\n",
        "\n",
        "    # Recherchez si la ligne existe dans df2 en fonction de la colonne \"airport\"\n",
        "    matching_row_df2 = df2[df2[partie1] == airport_df]\n",
        "\n",
        "    if not matching_row_df2.empty:\n",
        "      airport_df2 = matching_row_df2[partie1].iloc[0]\n",
        "      country_df2 = matching_row_df2[partie2].iloc[0]\n",
        "\n",
        "      # Calculez la similarité entre les éléments correspondants (vous pouvez personnaliser cette logique)\n",
        "      similarity = 1 if country_df == country_df2 else 0\n",
        "\n",
        "      # Ajoutez la ligne à la liste\n",
        "      result_rows.append([country_df, country_df2, similarity])\n",
        "\n",
        "  # Créez un DataFrame df3 à partir de la liste\n",
        "  df3 = pd.DataFrame(result_rows, columns=[ 'data_from_df', 'data_from_df2', 'similarity'])\n",
        "\n",
        "  # Affichez df3\n",
        "  print(df3)\n",
        "\n",
        "  # Enregistrer le DataFrame df3 dans un fichier CSV\n",
        "  df3.to_csv(f'Similarity_{i+1}.csv', index=False)\n",
        "\n",
        "  # Print a message indicating that the data has been saved\n",
        "  print(f'Data with similarity values has been saved to \\'Similarity_{i+1}.csv\\'')\n",
        "\n",
        "  # Mesurer le temps d'exécution final\n",
        "  temps_fin = time.time()\n",
        "  temps_execution = temps_fin - temps_debut\n",
        "  # Convertir le temps en minutes et secondes\n",
        "  minutes = int(temps_execution // 60)\n",
        "  secondes = int(temps_execution % 60)\n",
        "  # Formater le temps en chaîne de caractères\n",
        "  temps_formate = f\"{minutes} min {secondes} s\"\n",
        "\n",
        "  # Enregistrez le temps d'exécution formate dans un fichier texte\n",
        "  with open(f'temps_execution_{i+1}.txt', 'w') as fichier_temps:\n",
        "    fichier_temps.write(f'Temps d\\'exécution total : {temps_formate}')\n",
        "\n",
        "  # Affichez le temps d'exécution formate\n",
        "  print(f\"Temps d'exécution total : {temps_formate}\")"
      ],
      "metadata": {
        "id": "IFIw91VQksFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0oYz62lcZ3Y"
      },
      "source": [
        "**JSON FORMAT**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0 shot prompt**"
      ],
      "metadata": {
        "id": "oT7M8HV-is1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créez une variable pour stocker les noms de fichiers\n",
        "similarity_files = []\n",
        "\n",
        "# Create an empty list to store all JSON items\n",
        "all_json_items = []\n",
        "\n",
        "liste_examples = []\n",
        "liste_answer = []\n",
        "# Nombre total d'itérations (adaptez-le à votre cas)\n",
        "nombre_iterations = 3\n",
        "for i in range(nombre_iterations):\n",
        "  # Mesurer le temps d'exécution initial\n",
        "  temps_debut = time.time()\n",
        "  print(f\"*****************************Iteration {i+1}*********************************\")\n",
        "  premiere_iteration = True\n",
        "\n",
        "  # Convertissez le DataFrame en une liste à chaque itération\n",
        "  ma_liste = db.values.tolist()\n",
        "  elements_choisis = random.sample(ma_liste, 0)\n",
        "\n",
        "  print(f\"Éléments choisis: {elements_choisis}\")\n",
        "  for j in range(len(elements_choisis)):\n",
        "    Example_j = elements_choisis[j][0]\n",
        "    Answer_j = elements_choisis[j][1]\n",
        "    liste_examples.append(Example_j)\n",
        "    liste_answer.append(Answer_j)\n",
        "    #print(f\"Example_{j}: {Example_j}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Supprimez les éléments choisis de la liste principale\n",
        "  for element in elements_choisis:\n",
        "      ma_liste.remove(element)\n",
        "\n",
        "  print(f\"Reste de la liste: {ma_liste}\")\n",
        "\n",
        "  batch_size = 8\n",
        "  total_rows = len(ma_liste)\n",
        "  num_batches = (total_rows + batch_size - 1) // batch_size  # Calculating the number of batches\n",
        "\n",
        "  for batch_index in range(num_batches):\n",
        "    print(f\"Batch:\",{batch_index+1})\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = min((batch_index + 1) * batch_size, total_rows)\n",
        "    batch_list = ma_liste[start_index:end_index]\n",
        "    print(f\"Batch List: {batch_list}\")\n",
        "\n",
        "    # prendre la premiere colonne de la liste \"ma_liste\" et le mettre dans \"output_list\"\n",
        "    output_list = []\n",
        "    for row in batch_list:\n",
        "        output_list.append(row[0])\n",
        "\n",
        "    # Cette ligne de code transforme une liste d'éléments en une chaîne de caractères où les éléments sont séparés par des virgules et un espace.\n",
        "    formatted_output = ', '.join(output_list)\n",
        "\n",
        "    # Construisez le JSON avec des noms de PDG correctement formatés (avec des espaces)\n",
        "    ceos_json = []\n",
        "    for ceo_name in output_list:\n",
        "        ceos_json.append({partie1: ceo_name, partie2: 'valueee'})  # Remplacez 'value2' par la valeur appropriée\n",
        "\n",
        "    input_data = {\n",
        "        \"prompt\": f\"Act as Senior data analyst, \\n\\\n",
        "        I order you to focus carefully on my prompt before answering: \\n\\\n",
        "        complete the {partie2} of each one of this list: {formatted_output} \\n\\\n",
        "        Provide the result in JSON string format.\\n\\\n",
        "        and this is the format: {json.dumps(ceos_json)}\\n\\\n",
        "        you should provide me just {len(batch_list)} rows. \\n\\\n",
        "        If you don't know the answer please write 'unknown' \\n\\\n",
        "        If more than one answer fit for {partie2} write only the first option\"\n",
        "      }\n",
        "\n",
        "    print(f\"Prompt: {input_data}\")\n",
        "\n",
        "    output_prompt2 = replicate.run(\n",
        "        \"replicate/llama-2-70b-chat:58d078176e02c219e11eb4da5a02a7830a283b14cf8f94537af893ccff5ee781\", input=input_data)\n",
        "    full_response_prompt2 = \"\".join(output_prompt2)\n",
        "\n",
        "    print(f\"Replicate: {full_response_prompt2}\")\n",
        "\n",
        "    json_result_list = []\n",
        "    inside_json = False\n",
        "    json_string = \"\"\n",
        "    added_items = set()\n",
        "\n",
        "    for line in full_response_prompt2:\n",
        "        if line.strip().startswith('{'):\n",
        "            inside_json = True\n",
        "            json_string = line\n",
        "        elif inside_json:\n",
        "            json_string += line\n",
        "        if line.endswith('}'):\n",
        "            inside_json = False\n",
        "            try:\n",
        "                json_obj = json.loads(json_string)\n",
        "                json_str = json.dumps(json_obj)  # Convertir le dictionnaire en une chaîne JSON\n",
        "                if json_str not in added_items:  # Utiliser la chaîne JSON comme clé\n",
        "                    json_result_list.append(json_obj)\n",
        "                    print(json_result_list)\n",
        "                    added_items.add(json_str)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "    # Add the JSON items from this batch to the list of all JSON items\n",
        "    all_json_items.extend(json_result_list)\n",
        "\n",
        "    #print(\"all_json_items: \",all_json_items)\n",
        "\n",
        "    # Create a CSV file to save the JSON data for this iteration\n",
        "    csv_file_name = f\"output_{i+1}.csv\"\n",
        "\n",
        "    # Déterminez le mode d'ouverture en fonction de l'itération et premiere_iteration\n",
        "    if premiere_iteration:\n",
        "      mode = 'w'\n",
        "    else:\n",
        "      mode = 'a'\n",
        "\n",
        "    # Utilisez le mode déterminé pour ouvrir le fichier CSV\n",
        "    with open(csv_file_name, mode=mode, newline='') as csv_file:\n",
        "      fieldnames = [partie1, partie2]  # Définir les noms de champs pour le CSV\n",
        "      writer = csv.writer(csv_file)\n",
        "      # Si c'est la première itération, écrivez l'en-tête\n",
        "      if premiere_iteration:\n",
        "        writer.writerow(fieldnames)  # Écrire l'en-tête\n",
        "\n",
        "      # Write all JSON items to the CSV with removed double quotes\n",
        "      for json_item in json_result_list:\n",
        "        company = json_item[partie1].strip('\"')\n",
        "        ceo = json_item[partie2].strip('\"')  # Remove quotes around CEO\n",
        "        writer.writerow([company, ceo])\n",
        "\n",
        "\n",
        "    # Print a message indicating that the data has been saved for this iteration\n",
        "    print(f\"JSON data for iteration {i+1} has been saved to {csv_file_name}\")\n",
        "\n",
        "    premiere_iteration = False\n",
        "  # Assuming you have defined 'df' and 'csv_file_name' variables earlier in your code\n",
        "  df2 = pd.read_csv(f'output_{i+1}.csv')\n",
        "  # Créez une liste vide pour stocker les lignes de df3\n",
        "  result_rows = []\n",
        "\n",
        "  # Parcourez les lignes de df\n",
        "  for index, row_df in db.iterrows():\n",
        "    airport_df = row_df[partie1]\n",
        "    country_df = row_df[partie2]\n",
        "\n",
        "    # Recherchez si la ligne existe dans df2 en fonction de la colonne \"airport\"\n",
        "    matching_row_df2 = df2[df2[partie1] == airport_df]\n",
        "\n",
        "    if not matching_row_df2.empty:\n",
        "      airport_df2 = matching_row_df2[partie1].iloc[0]\n",
        "      country_df2 = matching_row_df2[partie2].iloc[0]\n",
        "\n",
        "      # Calculez la similarité entre les éléments correspondants (vous pouvez personnaliser cette logique)\n",
        "      similarity = 1 if country_df == country_df2 else 0\n",
        "\n",
        "      # Ajoutez la ligne à la liste\n",
        "      result_rows.append([country_df, country_df2, similarity])\n",
        "\n",
        "  # Créez un DataFrame df3 à partir de la liste\n",
        "  df3 = pd.DataFrame(result_rows, columns=[ 'data_from_df', 'data_from_df2', 'similarity'])\n",
        "\n",
        "  # Affichez df3\n",
        "  print(df3)\n",
        "\n",
        "  # Enregistrer le DataFrame df3 dans un fichier CSV\n",
        "  df3.to_csv(f'Similarity_{i+1}.csv', index=False)\n",
        "\n",
        "  # Print a message indicating that the data has been saved\n",
        "  print(f'Data with similarity values has been saved to \\'Similarity_{i+1}.csv\\'')\n",
        "\n",
        "  # Mesurer le temps d'exécution final\n",
        "  temps_fin = time.time()\n",
        "  temps_execution = temps_fin - temps_debut\n",
        "  # Convertir le temps en minutes et secondes\n",
        "  minutes = int(temps_execution // 60)\n",
        "  secondes = int(temps_execution % 60)\n",
        "  # Formater le temps en chaîne de caractères\n",
        "  temps_formate = f\"{minutes} min {secondes} s\"\n",
        "\n",
        "  # Enregistrez le temps d'exécution formate dans un fichier texte\n",
        "  with open(f'temps_execution_{i+1}.txt', 'w') as fichier_temps:\n",
        "    fichier_temps.write(f'Temps d\\'exécution total : {temps_formate}')\n",
        "\n",
        "  # Affichez le temps d'exécution formate\n",
        "  print(f\"Temps d'exécution total : {temps_formate}\")\n"
      ],
      "metadata": {
        "id": "RXiXqckJiPI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade replicate\n"
      ],
      "metadata": {
        "id": "v1iDha6v6GG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TBjSZtipTxZ"
      },
      "outputs": [],
      "source": [
        "# Créez une variable pour stocker les noms de fichiers\n",
        "similarity_files = []\n",
        "\n",
        "# Create an empty list to store all JSON items\n",
        "all_json_items = []\n",
        "\n",
        "liste_examples = []\n",
        "liste_answer = []\n",
        "# Nombre total d'itérations (adaptez-le à votre cas)\n",
        "nombre_iterations = 3\n",
        "for i in range(nombre_iterations):\n",
        "  # Mesurer le temps d'exécution initial\n",
        "  temps_debut = time.time()\n",
        "  print(f\"*****************************Iteration {i+1}*********************************\")\n",
        "  premiere_iteration = True\n",
        "\n",
        "  # Convertissez le DataFrame en une liste à chaque itération\n",
        "  ma_liste = db.values.tolist()\n",
        "  elements_choisis = random.sample(ma_liste, 3)\n",
        "\n",
        "  print(f\"Éléments choisis: {elements_choisis}\")\n",
        "  for j in range(len(elements_choisis)):\n",
        "    Example_j = elements_choisis[j][0]\n",
        "    Answer_j = elements_choisis[j][1]\n",
        "    liste_examples.append(Example_j)\n",
        "    liste_answer.append(Answer_j)\n",
        "    #print(f\"Example_{j}: {Example_j}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Supprimez les éléments choisis de la liste principale\n",
        "  for element in elements_choisis:\n",
        "      ma_liste.remove(element)\n",
        "\n",
        "  print(f\"Reste de la liste: {ma_liste}\")\n",
        "\n",
        "  batch_size = 8\n",
        "  total_rows = len(ma_liste)\n",
        "  num_batches = (total_rows + batch_size - 1) // batch_size  # Calculating the number of batches\n",
        "\n",
        "  for batch_index in range(num_batches):\n",
        "    print(f\"Batch:\",{batch_index+1})\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = min((batch_index + 1) * batch_size, total_rows)\n",
        "    batch_list = ma_liste[start_index:end_index]\n",
        "    print(f\"Batch List: {batch_list}\")\n",
        "\n",
        "    # prendre la premiere colonne de la liste \"ma_liste\" et le mettre dans \"output_list\"\n",
        "    output_list = []\n",
        "    for row in batch_list:\n",
        "        output_list.append(row[0])\n",
        "\n",
        "    # Cette ligne de code transforme une liste d'éléments en une chaîne de caractères où les éléments sont séparés par des virgules et un espace.\n",
        "    formatted_output = ', '.join(output_list)\n",
        "\n",
        "    # Construisez le JSON avec des noms de PDG correctement formatés (avec des espaces)\n",
        "    ceos_json = []\n",
        "    for ceo_name in output_list:\n",
        "        ceos_json.append({partie1: ceo_name, partie2: 'valueee'})  # Remplacez 'value2' par la valeur appropriée\n",
        "\n",
        "\n",
        "\n",
        "    input_data = {\n",
        "        \"prompt\": f\"Act as Senior data analyst, \\n\\\n",
        "        Look at this examples: \\n\\\n",
        "        Example: {liste_examples[0]} \\n\\\n",
        "        Answer: {liste_answer[0]}\\n\\\n",
        "        Example: {liste_examples[1]} \\n\\\n",
        "        Answer: {liste_answer[1]}\\n\\\n",
        "        Example: {liste_examples[2]} \\n\\\n",
        "        Answer: {liste_answer[2]}\\n\\\n",
        "        I order you to focus carefully on my prompt before answering: \\n\\\n",
        "        complete the {partie2} of each one of this list: {formatted_output} \\n\\\n",
        "        Provide the result in JSON string format.\\n\\\n",
        "        and this is the format: {json.dumps(ceos_json)}\\n\\\n",
        "        you should provide me just {len(batch_list)} rows. \\n\\\n",
        "        If you don't know the answer please write 'unknown' \\n\\\n",
        "        If more than one answer fit for {partie2} write only the first option\"\n",
        "      }\n",
        "\n",
        "    print(f\"Prompt: {input_data}\")\n",
        "\n",
        "    output_prompt2 = replicate.run(\n",
        "        \"replicate/llama-2-70b-chat:58d078176e02c219e11eb4da5a02a7830a283b14cf8f94537af893ccff5ee781\", input=input_data)\n",
        "    full_response_prompt2 = \"\".join(output_prompt2)\n",
        "\n",
        "    print(f\"Replicate: {full_response_prompt2}\")\n",
        "\n",
        "    json_result_list = []\n",
        "    inside_json = False\n",
        "    json_string = \"\"\n",
        "    added_items = set()\n",
        "\n",
        "    for line in full_response_prompt2:\n",
        "        if line.strip().startswith('{'):\n",
        "            inside_json = True\n",
        "            json_string = line\n",
        "        elif inside_json:\n",
        "            json_string += line\n",
        "        if line.endswith('}'):\n",
        "            inside_json = False\n",
        "            try:\n",
        "                json_obj = json.loads(json_string)\n",
        "                json_str = json.dumps(json_obj)  # Convertir le dictionnaire en une chaîne JSON\n",
        "                if json_str not in added_items:  # Utiliser la chaîne JSON comme clé\n",
        "                    json_result_list.append(json_obj)\n",
        "                    print(json_result_list)\n",
        "                    added_items.add(json_str)\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "    # Add the JSON items from this batch to the list of all JSON items\n",
        "    all_json_items.extend(json_result_list)\n",
        "\n",
        "    #print(\"all_json_items: \",all_json_items)\n",
        "\n",
        "    # Create a CSV file to save the JSON data for this iteration\n",
        "    csv_file_name = f\"output_{i+1}.csv\"\n",
        "\n",
        "    # Déterminez le mode d'ouverture en fonction de l'itération et premiere_iteration\n",
        "    if premiere_iteration:\n",
        "      mode = 'w'\n",
        "    else:\n",
        "      mode = 'a'\n",
        "\n",
        "    # Utilisez le mode déterminé pour ouvrir le fichier CSV\n",
        "    with open(csv_file_name, mode=mode, newline='') as csv_file:\n",
        "      fieldnames = [partie1, partie2]  # Définir les noms de champs pour le CSV\n",
        "      writer = csv.writer(csv_file)\n",
        "      # Si c'est la première itération, écrivez l'en-tête\n",
        "      if premiere_iteration:\n",
        "        writer.writerow(fieldnames)  # Écrire l'en-tête\n",
        "\n",
        "      # Write all JSON items to the CSV with removed double quotes\n",
        "      for json_item in json_result_list:\n",
        "        company = json_item[partie1].strip('\"')\n",
        "        ceo = json_item[partie2].strip('\"')  # Remove quotes around CEO\n",
        "        writer.writerow([company, ceo])\n",
        "\n",
        "\n",
        "    # Print a message indicating that the data has been saved for this iteration\n",
        "    print(f\"JSON data for iteration {i+1} has been saved to {csv_file_name}\")\n",
        "\n",
        "    premiere_iteration = False\n",
        "  # Assuming you have defined 'df' and 'csv_file_name' variables earlier in your code\n",
        "  df2 = pd.read_csv(f'output_{i+1}.csv')\n",
        "  # Créez une liste vide pour stocker les lignes de df3\n",
        "  result_rows = []\n",
        "\n",
        "  # Parcourez les lignes de df\n",
        "  for index, row_df in db.iterrows():\n",
        "    airport_df = row_df[partie1]\n",
        "    country_df = row_df[partie2]\n",
        "\n",
        "    # Recherchez si la ligne existe dans df2 en fonction de la colonne \"airport\"\n",
        "    matching_row_df2 = df2[df2[partie1] == airport_df]\n",
        "\n",
        "    if not matching_row_df2.empty:\n",
        "      airport_df2 = matching_row_df2[partie1].iloc[0]\n",
        "      country_df2 = matching_row_df2[partie2].iloc[0]\n",
        "\n",
        "      # Calculez la similarité entre les éléments correspondants (vous pouvez personnaliser cette logique)\n",
        "      similarity = 1 if country_df == country_df2 else 0\n",
        "\n",
        "      # Ajoutez la ligne à la liste\n",
        "      result_rows.append([country_df, country_df2, similarity])\n",
        "\n",
        "  # Créez un DataFrame df3 à partir de la liste\n",
        "  df3 = pd.DataFrame(result_rows, columns=[ 'data_from_df', 'data_from_df2', 'similarity'])\n",
        "\n",
        "  # Affichez df3\n",
        "  print(df3)\n",
        "\n",
        "  # Enregistrer le DataFrame df3 dans un fichier CSV\n",
        "  df3.to_csv(f'Similarity_{i+1}.csv', index=False)\n",
        "\n",
        "  # Print a message indicating that the data has been saved\n",
        "  print(f'Data with similarity values has been saved to \\'Similarity_{i+1}.csv\\'')\n",
        "\n",
        "  # Mesurer le temps d'exécution final\n",
        "  temps_fin = time.time()\n",
        "  temps_execution = temps_fin - temps_debut\n",
        "  # Convertir le temps en minutes et secondes\n",
        "  minutes = int(temps_execution // 60)\n",
        "  secondes = int(temps_execution % 60)\n",
        "  # Formater le temps en chaîne de caractères\n",
        "  temps_formate = f\"{minutes} min {secondes} s\"\n",
        "\n",
        "  # Enregistrez le temps d'exécution formate dans un fichier texte\n",
        "  with open(f'temps_execution_{i+1}.txt', 'w') as fichier_temps:\n",
        "    fichier_temps.write(f'Temps d\\'exécution total : {temps_formate}')\n",
        "\n",
        "  # Affichez le temps d'exécution formate\n",
        "  print(f\"Temps d'exécution total : {temps_formate}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjTAMEhfpYsB",
        "outputId": "656354d0-f975-4c46-e6d0-4a97d8482f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats enregistrés dans 'resultat.txt'\n"
          ]
        }
      ],
      "source": [
        "# Liste pour stocker les résultats individuels\n",
        "results = []\n",
        "# Chaîne pour stocker les résultats sous forme de texte\n",
        "result_str = \"\"\n",
        "# Dictionnaire pour stocker les résultats\n",
        "resultats = {}\n",
        "# Parcourez les fichiers pour chaque itération\n",
        "for i in range(3):\n",
        "  # Chargez le fichier \"Similarity_airportToCountry_{i+1}.csv\" en tant que DataFrame pandas\n",
        "  nom_fichier = f'Similarity_{i+1}.csv'\n",
        "  similarity_file = pd.read_csv(nom_fichier)\n",
        "  # Calculez la somme de la troisième colonne\n",
        "  sum_of_column_3 = similarity_file['similarity'].sum()\n",
        "  # Obtenez le nombre de lignes\n",
        "  num_rows = len(similarity_file)\n",
        "  result = sum_of_column_3 / num_rows\n",
        "  result_str += f\"The accuracy of {nom_fichier} : {result}\\n\"\n",
        "  results.append(result)  # Ajoutez le résultat à la liste\n",
        "\n",
        "# Calculez la moyenne des résultats\n",
        "average_result = np.average(results)\n",
        "result_str += f\"The average : {average_result}\\n\"\n",
        "ecart_type = np.std(results)\n",
        "result_str += f\"The standard deviation : {ecart_type}\\n\"\n",
        "\n",
        "# Enregistrez les résultats dans un fichier texte\n",
        "with open(\"resultat.txt\", \"w\") as file:\n",
        "  file.write(result_str)\n",
        "  print(\"Résultats enregistrés dans 'resultat.txt'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**++++++++++++++++++++TEST+++++++++++++++++++++**"
      ],
      "metadata": {
        "id": "To04BClUX9Gl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFREnMH7DeBj",
        "outputId": "f0618475-bee9-481a-c066-22bcfdf97ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "North Rhine-Westphalia \t\t North Rhine-Westphalia, Germany \t\t Score: 0.9664\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Two lists of words\n",
        "word1 = ['North Rhine-Westphalia']\n",
        "word2 = ['North Rhine-Westphalia, Germany']\n",
        "\n",
        "\n",
        "\n",
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(word1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(word2, convert_to_tensor=True)\n",
        "\n",
        "#Compute cosine-similarities\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "#Output the pairs with their score\n",
        "for i in range(len(word1)):\n",
        "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(word1[i], word2[i], cosine_scores[i][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi1BMln9DnA0"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RvCSmz8AFvy",
        "outputId": "848e5090-b7cb-4474-ab10-4ab52a306e21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.edit_distance(\"North Rhine-Westphalia\", \"North Rhine-Westphalia, Germany\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObvTiK8/+jsb0thpMF0m5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}